{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from configuration import Config\n",
    "from modeling import CasualLM\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    vocab_size=5000,\n",
    "    num_hiddens=256,\n",
    "    num_layers=12,\n",
    "    num_heads=16,\n",
    "    num_mlp_intermediate=1024,\n",
    "    max_context_length=1024,\n",
    "    dropout=0.1\n",
    ")\n",
    "\n",
    "model = CasualLM(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 测试推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
      "        [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
      "tensor([[[-0.1078,  1.1004,  0.5563,  ..., -0.2622, -0.3747, -0.2667],\n",
      "         [ 0.3528, -0.1032, -0.6390,  ..., -0.3498,  0.4159, -0.2350],\n",
      "         [ 0.4912, -0.6048,  0.0915,  ...,  0.0234, -0.5541,  0.1849],\n",
      "         ...,\n",
      "         [ 0.3970,  0.6454,  0.3539,  ...,  0.1974, -0.0288,  0.0264],\n",
      "         [ 0.7619,  0.3111,  0.6169,  ...,  0.2740,  0.3187, -0.3959],\n",
      "         [ 0.2494, -0.1373,  0.7362,  ..., -0.2177,  0.3799, -0.1806]],\n",
      "\n",
      "        [[-1.0070,  0.9892,  0.3765,  ...,  0.0530, -0.1038, -0.4448],\n",
      "         [-0.2819,  0.3956, -0.4799,  ...,  0.1168, -0.4340, -0.4608],\n",
      "         [-0.3284,  0.4360,  0.1284,  ...,  0.0734, -0.1911,  0.1953],\n",
      "         ...,\n",
      "         [ 0.6058,  0.7129,  0.4267,  ...,  0.5368, -0.4061, -0.3195],\n",
      "         [ 0.2839,  0.8878,  0.4793,  ...,  0.2028,  0.3346, -0.4606],\n",
      "         [-0.0501,  0.2916,  0.6988,  ...,  0.1600,  0.3302, -0.3605]]],\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0,10).repeat(2, 2)\n",
    "print(x)\n",
    "y = model(x)\n",
    "print(y.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 打印参数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12030344\n"
     ]
    }
   ],
   "source": [
    "print(sum([param.nelement() for param in model.parameters()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 测试训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 定义超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 4\n",
    "trainer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 构造训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = torch.randint(0, 10, (100, 15))\n",
    "labels = torch.randint(0, 10, (100, 15))\n",
    "labels[:, :10] = -100\n",
    "dataset = TensorDataset(features, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 定义损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.7146, grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossfn = torch.nn.CrossEntropyLoss()\n",
    "lossfn(model(features).logits.transpose(1, 2), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个epoch：loss大小为7.20601749420166\n",
      "第1个epoch：loss大小为6.11973762512207\n",
      "第2个epoch：loss大小为5.319315433502197\n",
      "第3个epoch：loss大小为4.695573329925537\n",
      "第4个epoch：loss大小为4.1675238609313965\n",
      "第5个epoch：loss大小为3.748037815093994\n",
      "第6个epoch：loss大小为3.4087507724761963\n",
      "第7个epoch：loss大小为3.163405656814575\n",
      "第8个epoch：loss大小为2.9779975414276123\n",
      "第9个epoch：loss大小为2.837214469909668\n",
      "第10个epoch：loss大小为2.7445359230041504\n",
      "第11个epoch：loss大小为2.666536331176758\n",
      "第12个epoch：loss大小为2.6032042503356934\n",
      "第13个epoch：loss大小为2.565561056137085\n",
      "第14个epoch：loss大小为2.5243537425994873\n",
      "第15个epoch：loss大小为2.5040407180786133\n",
      "第16个epoch：loss大小为2.4810259342193604\n",
      "第17个epoch：loss大小为2.454805850982666\n",
      "第18个epoch：loss大小为2.4362950325012207\n",
      "第19个epoch：loss大小为2.4223792552948\n",
      "第20个epoch：loss大小为2.4069271087646484\n",
      "第21个epoch：loss大小为2.3958041667938232\n",
      "第22个epoch：loss大小为2.398460626602173\n",
      "第23个epoch：loss大小为2.38771653175354\n",
      "第24个epoch：loss大小为2.3798112869262695\n",
      "第25个epoch：loss大小为2.3744165897369385\n",
      "第26个epoch：loss大小为2.361802339553833\n",
      "第27个epoch：loss大小为2.362191677093506\n",
      "第28个epoch：loss大小为2.3550472259521484\n",
      "第29个epoch：loss大小为2.3451409339904785\n",
      "第30个epoch：loss大小为2.351855754852295\n",
      "第31个epoch：loss大小为2.343228340148926\n",
      "第32个epoch：loss大小为2.3371567726135254\n",
      "第33个epoch：loss大小为2.336557149887085\n",
      "第34个epoch：loss大小为2.3297719955444336\n",
      "第35个epoch：loss大小为2.317432403564453\n",
      "第36个epoch：loss大小为2.3224966526031494\n",
      "第37个epoch：loss大小为2.3187758922576904\n",
      "第38个epoch：loss大小为2.3215150833129883\n",
      "第39个epoch：loss大小为2.3125269412994385\n",
      "第40个epoch：loss大小为2.3136165142059326\n",
      "第41个epoch：loss大小为2.3037071228027344\n",
      "第42个epoch：loss大小为2.3050713539123535\n",
      "第43个epoch：loss大小为2.313800096511841\n",
      "第44个epoch：loss大小为2.299724578857422\n",
      "第45个epoch：loss大小为2.3050076961517334\n",
      "第46个epoch：loss大小为2.2917516231536865\n",
      "第47个epoch：loss大小为2.291400671005249\n",
      "第48个epoch：loss大小为2.2935516834259033\n",
      "第49个epoch：loss大小为2.2820653915405273\n",
      "第50个epoch：loss大小为2.2801990509033203\n",
      "第51个epoch：loss大小为2.28226375579834\n",
      "第52个epoch：loss大小为2.2829642295837402\n",
      "第53个epoch：loss大小为2.2732326984405518\n",
      "第54个epoch：loss大小为2.2756669521331787\n",
      "第55个epoch：loss大小为2.2704713344573975\n",
      "第56个epoch：loss大小为2.269651174545288\n",
      "第57个epoch：loss大小为2.258056640625\n",
      "第58个epoch：loss大小为2.259089469909668\n",
      "第59个epoch：loss大小为2.2588400840759277\n",
      "第60个epoch：loss大小为2.258955240249634\n",
      "第61个epoch：loss大小为2.251671314239502\n",
      "第62个epoch：loss大小为2.2478137016296387\n",
      "第63个epoch：loss大小为2.2580058574676514\n",
      "第64个epoch：loss大小为2.245392322540283\n",
      "第65个epoch：loss大小为2.24554443359375\n",
      "第66个epoch：loss大小为2.251089334487915\n",
      "第67个epoch：loss大小为2.2363178730010986\n",
      "第68个epoch：loss大小为2.235119581222534\n",
      "第69个epoch：loss大小为2.2345528602600098\n",
      "第70个epoch：loss大小为2.2337639331817627\n",
      "第71个epoch：loss大小为2.2396597862243652\n",
      "第72个epoch：loss大小为2.223853588104248\n",
      "第73个epoch：loss大小为2.213188886642456\n",
      "第74个epoch：loss大小为2.2126779556274414\n",
      "第75个epoch：loss大小为2.2062063217163086\n",
      "第76个epoch：loss大小为2.221390724182129\n",
      "第77个epoch：loss大小为2.2011096477508545\n",
      "第78个epoch：loss大小为2.2023091316223145\n",
      "第79个epoch：loss大小为2.2020699977874756\n",
      "第80个epoch：loss大小为2.1974053382873535\n",
      "第81个epoch：loss大小为2.1930925846099854\n",
      "第82个epoch：loss大小为2.1890907287597656\n",
      "第83个epoch：loss大小为2.199939250946045\n",
      "第84个epoch：loss大小为2.18977952003479\n",
      "第85个epoch：loss大小为2.1721153259277344\n",
      "第86个epoch：loss大小为2.197456121444702\n",
      "第87个epoch：loss大小为2.1824846267700195\n",
      "第88个epoch：loss大小为2.18210506439209\n",
      "第89个epoch：loss大小为2.1725199222564697\n",
      "第90个epoch：loss大小为2.19270396232605\n",
      "第91个epoch：loss大小为2.1699376106262207\n",
      "第92个epoch：loss大小为2.172346830368042\n",
      "第93个epoch：loss大小为2.162379503250122\n",
      "第94个epoch：loss大小为2.1669747829437256\n",
      "第95个epoch：loss大小为2.176384210586548\n",
      "第96个epoch：loss大小为2.1751062870025635\n",
      "第97个epoch：loss大小为2.1606171131134033\n",
      "第98个epoch：loss大小为2.1605844497680664\n",
      "第99个epoch：loss大小为2.1535980701446533\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    for feature, label in dataloader:\n",
    "        loss = lossfn(model(feature).logits.transpose(1, 2), label)\n",
    "        trainer.zero_grad()\n",
    "        loss.backward()\n",
    "        trainer.step()\n",
    "    with torch.no_grad():\n",
    "        loss = lossfn(model(features).logits.transpose(1, 2), labels)\n",
    "        print(f\"第{i}个epoch：loss大小为{loss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
